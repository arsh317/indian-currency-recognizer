{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n\nfrom PIL import Image\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HEIGHT = 224\nWIDTH = 224\n\nbase_model = MobileNetV2(weights='imagenet', \n                      include_top=False, \n                      input_shape=(HEIGHT, WIDTH, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Activation, Flatten, Dropout\nfrom keras.models import Sequential, Model\n\ndef build_finetune_model(base_model, dropout, fc_layers, num_classes):\n    for layer in base_model.layers[:-4]:\n        layer.trainable = False\n\n    x = base_model.output\n    x = Flatten()(x)\n    for fc in fc_layers:\n        # New FC layer, random init\n        x = Dense(fc, activation='relu')(x) \n        x = Dropout(dropout)(x)\n\n    # New softmax layer\n    predictions = Dense(num_classes, activation='softmax')(x) \n    \n    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n\n    return finetune_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.mobilenet_v2 import preprocess_input\n\n\nTRAIN_DIR = \"../input/currency-train-test/train_test/train_data\"\nHEIGHT = 224\nWIDTH = 224\nBATCH_SIZE = 8\n\ntrain_datagen =  ImageDataGenerator(\n       preprocessing_function=preprocess_input,\n       zoom_range = 0.3,\n       rotation_range=90,\n       horizontal_flip=True,\n       vertical_flip=True\n    )\n\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n                                                    target_size=(HEIGHT, WIDTH), \n                                                    batch_size=BATCH_SIZE)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DIR = \"../input/currency-train-test/train_test/test_data\"\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, \n                                                    target_size=(HEIGHT, WIDTH), \n                                                    batch_size=BATCH_SIZE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FC_LAYERS = [128]\ndropout = 0.4\n\nfinetune_model = build_finetune_model(base_model, \n                                      dropout=dropout, \n                                      fc_layers=FC_LAYERS, \n                                      num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD, Adam\n\nNUM_EPOCHS = 10\nBATCH_SIZE = 8\nnum_train_images = 4206\nnum_test_images = 1232\n\n\nadam = Adam(lr=0.0001)\nfinetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n                             steps_per_epoch=num_train_images // BATCH_SIZE,\n                             validation_steps=num_test_images // BATCH_SIZE,\n                             validation_data = test_generator)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_model.fit_generator(train_generator, epochs=5, workers=8, \n                             steps_per_epoch=num_train_images // BATCH_SIZE,\n                             validation_steps=num_test_images // BATCH_SIZE,\n                             validation_data = test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_model.fit_generator(train_generator, epochs=7, workers=8, \n                             steps_per_epoch=num_train_images // BATCH_SIZE,\n                             validation_steps=num_test_images // BATCH_SIZE,\n                             validation_data = test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = Adam(lr=0.00001)\nfinetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\nfinetune_model.fit_generator(train_generator, epochs=10, workers=8, \n                             steps_per_epoch=num_train_images // BATCH_SIZE,\n                             validation_steps=num_test_images // BATCH_SIZE,\n                             validation_data = test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = Adam(lr=0.000001)\nfinetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_model.fit_generator(train_generator, epochs=5, workers=8, \n                             steps_per_epoch=num_train_images // BATCH_SIZE,\n                             validation_steps=num_test_images // BATCH_SIZE,\n                             validation_data = test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_model.fit_generator(train_generator, epochs=5, workers=8, \n                             steps_per_epoch=200,\n                             validation_steps=num_test_images // BATCH_SIZE,\n                             validation_data = test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n\nfinetune_model.save('/kaggle/working/my_model1.h5')  # creates a HDF5 file 'my_model.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('my_model1.hdf')\n\nno_to_note={0:\"100\",1:\"50\",2:\"10\",3:\"2000\",4:\"200\",5:\"20\",6:\"500\",7:\"50\",8:\"100\",9:\"No note\"}\nimg=\"F:/Capstone Project/Currency recognition/currency_dataset/20_old/319.jpg\"\n\nimport cv2,numpy as np\n\nimg = Image.open(img)\nimg = np. array(img)\nimg=cv2.resize(img,(224,224))\nimg=preprocess_input(img)\n#from matplotlib import pyplot as plt\n#plt.imshow(img, interpolation='nearest')\n#plt.show()\n\nimg = np.expand_dims(img, axis=0)\n\narr=model.predict(img)\nprint(arr[0][0])\n\nmx,ind=arr[0][0],0\nfor i in range(10):\n    if(arr[0][i]>mx):\n        mx,ind=arr[0][i],i\n        \nprint(no_to_note[ind])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\nFileLinks('.') #lists all downloadable files on server","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}